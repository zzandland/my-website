# Operating Systems 9
## Chapter 9: Virtual Memory
<hr>

Virtual memory 기법은 전적으로 운영체제가 관여한다.

#### Demand Paging

프로세스가 시작될때 필요한 모든 page를 처음부터 올리는것이 아니라 특정 page가 필요할때만 메모리에 올림으로 필요한 메모리의 양이 줄어든다.

I/O 양이 감소한다. 사실 프로그램의 대부분의 코드는 사용자가 원치 않는 행동을 하지 못하도록 방어하는 코드들인데, 이런 코드들은 런타임중 사용되는 일이 드물다. 필요한 page만 메모리에 올림으로써 디스크에서 적게 읽어온다.

따라서 multiprogramming 환경에서 더 많은 프로세스를 올릴수 있고, 빠른 응답시간을 기대할수 있다.

Page table에서 valid/invalid bit을 사용하여 다음을 식별한다.
1. 사용되지 않는 주소 영역.
2. Page가 physical memory에 없는 경우. 이런 경우는 swap area에 있다.

#### Page Fault

> **Page Fault**: Page table을 통해 주소 변환을 할때 invalid bit이 set되 있는 경우 (physical memory)에 요청한 frame이 없는 경우.

*Page fault*가 발생하면 swap in을 해야하고 이것은 I/O 작업이기 때문에 커널모드로 전환된다.

1. Invalid page를 접근하면 MMU가 *page fault trap*을 발생시킴.
2. 커널모드로 전환후 *page fault handler* 호출.
3. 잘못된 주소거나 사용하지 않는 주소거나 protection bit에서 읽을 권한이 없는경우 abort.
4. Empty frame을 획득 (없는경우 사용중인 frame 하나를 대체한다).
5. 해당 frame을 디스크에서 physical memory로 읽어온다.
  1. Disk I/O가 끝날때까지 이 프로세스는 suspended 상태가 되고 I/O ready queue로 이동.
  2. Memory로 읽어오는 작업이 끝났을때 다시 커널모드로 돌아가 page table entry의 valid bit을 set.
  3. 프로세스를 다시 ready queue에 집어넣음.
6. 프로세스가 다시 CPU를 사용할때 중단 되었던 instruction을 재개.

> Page Fault Rate 0 <= p <= 1 (일반적으로 0.02정도이다)
> - if p = 0, no page faults
> - if p = 1, every reference is a fault

#### Page Replacement

빈 frame이 없는 경우는 어떤 frame을 swap out할지 결정해야한다. **Replacement algorithm**은 *fault rate*를 최소화 하는것이 목표.

1. Swap out할 frame을 결정한후, 그 frame에 있는 메모리의 변경된 정보가 있는지 확인한다.
  - 변경된 정보가 있으면 그 frame의 데이터를 디스크에 write해준다.
  - 없으면 그냥 지우면 된다.
2. 지워진 frame의 page를 page table entry에서 invalid bit으로 set.
3. 필요한 page를 비운 frame에다가 저장.
4. 새로 올라온 frame의 page를 page table entry에서 valid bit으로 set.

#### Optimal Algorithm

> **Offline Algorithm** (Belady's optimal algorithm, MIN, OPT): 미래에 사용될 page들을 모두 다 안다고 가정하는 경우, 가장 먼 미래에 참조되는 page를 우선적으로 replace한다.

물론 이 방식을 실제로 사용할수는 없지만 (미래를 완벽하게 예측불가) 최대한 얼마나 효율적으로 replace를 할지 upper bound 기준점이 되어준다.

#### FIFO Algorithm

먼저 메모리에 올라온 page를 먼저 replace한다.

> **FIFO Anomaly** (Belady's Anomaly): FIFO algorithm에서 사용 가능한 frame의 수가 늘어날수록 page fault rate가 늘어나는 현상.

#### LRU Algorithm

Least Recently Used: 가장 오래 전에 참조된 page를 replace한다. 하지만 과거에 얼마나 많이 참조되었는지는 고려하지 않는다.

> 구현 방법: 연결 리스트로 큐를 구현한후, 참조되는 노드는 잘라서 가장 끝으로 보내주고, 가장 앞에 있는 노드를 내보낸다. 시간 복잡도 O(1)으로 모든 작업이 구현가능.

#### LFU Algorithm

Least Frequently Used: 가장 reference count가 낮은 페이지를 replace. 만약 복수의 page가 reference count가 같은 경우 native LFU algorithm에서는 임의로 삭제하지만, 성능 향상을 위해 LRU를 사용할수 있다. 단점은 미래에 자주 사용될 page라도 과거로만 보았을때 reference count가 낮기에 우선적으로 replace 된다.

> 구현 방법: 힙으로 구현할 경우 모든 작업을 O(log n)으로 구현 가능하지만, 각자 reference count를 독자적인 LRU 로 구현을 하면 모든 작업이 O(1)으로 구현이 가능하다.

#### Caching

한정된 빠른 공간 (cache)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 돌려주는 방법. Paging에서는 TLB의 구현, CPU의 L1~3 cache memory, disk I/O를 cache하는 buffer memory, web caching (네트워크 콜이 느리기 때문에 동일한 내용이면 Webstorage에 저장한 내용을 가져다줌) 등 다양한 분야에서 사용한다.

Replacement algorithm에서 삭제할 항목을 결정하는 작업의 시간 복잡도는 O(1) 이거나 O(log n)이여만 사용 효율성이 있다.

#### Clock Algorithm

Paging system에서는 page가 physical memory에 있는 경우 (hit)은 OS의 관여가 없기 때문에 가장 오래전에 참조된 page가 무엇인지 (LRU) 혹은 가장 적게 참조된 page가 무엇인지 (LFU) 알수가 없기에 clock algorithm을 사용한다. 언제나 가장 오래전에 참조된 page를 찾지는 못하지만 approximately 찾는다.

Second chance algorithm, NUR (Not Used Recently) algorithm이라고도 불림.

1. 각 page들은 reference bit을 가지고 circular list의 모양을 가진다 (가장 끝 인덱스로부터 처음 인덱스로 이어짐).
  - Page가 참조될때 0으로 set 되있다면 1로 바꿔준다.
2. Replace를 해야할때 마지막으로 algorithm이 호출됬을 때의 인덱스로부터 재개 하며 인덱스의 reference bit이: 
  - 1일 경우 0으로 set을 한후 다음 인덱스로 이동
  - 0일 경우 그 인덱스의 page를 교체하고 reference bit을 1로 set.

Modified bit (최근에 I/O 작업을 통해 변경됬음을 의미)도 함께 사용하여 I/O 작업이 필요한 페이지는 되도록 교체하지 않도록 할수도 있다.

#### Page Frame Allocation

> **Global Replacement**: 프로세스가 더 많은 page가 필요할 경우 다른 프로세스의 frame들도 교체하여 프로세스 별 frame 할당량을 조절한다.

> **Local Replacement**: 프로세스마다 할당되는 page frame 갯수가 있고, 자신에게 할당된 frame 내에서만 교체하는 방법. 

> **Allocation Problem**: 각 프로세스에 몇개의 page frame을 할당할것인지에 대해 묻는 문제. 만약 특정 프로세스가 계속 여러 page를 요청을 해서 frame을 독차지 하는 것도 막는다.

여러 경우에 따라 최소한 다같이 할당되어야 하는 frame의 수가 있다.
1. 명령어 수행을 할때 명령어, 데이터 등 여러 페이지를 동시에 참조.
2. Loop를 구성하는 page들은 다같이 할당되지 않으면 매 loop 할때마다 page fault가 발생함으로 심각하게 느려진다.

Allocation Scheme
1. **Equal Allocation**: 모든 프로세스에 동일한 갯수의 frame을 할당한다.
2. **Proportional Allocation**: 프로세스의 크기에 비례하여 할당 하는법.
3. **Priority Allocation**: 프로세스의 우선도에 비례하여 할당 하는법.

#### Thrashing

프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당 받지 못한 경우 발생한다.

Degree of multiprogramming (how many processes run concurrently)가 높아지면 그만큼 ready queue에서 바로 CPU를 사용하기를 기다리는 프로세스의 수가 늘어나기에 CPU utilization이 증가한다.

하지만 일정수준의 degree를 넘기는 순간 프로세스가 필요한 page를 가져오기 위해 swapping을 하는 빈번도가 급증하여 오히려 CPU utilization이 급감한다. 즉 CPU에 올라오는 대부분의 프로세스들이 swapping I/O 작업을 하게 된다.

#### Working Set Model

> **Locality Set** (Working Set): 프로세스가 일정 시간동안 집중적으로 참조하는 page들의 집합. 원활한 수행을 위하여 다같이 할당이 되어야만 한다. Degree of multiprogramming이 너무 높아지는것을 막아줌으로 thrashing을 방지한다.

특정 시간동안 참조되지 않은 page는 working set에서 제외가 되며, 만약 그 기간 내 참조가 되었다면 참조가 된 그 시점부터 다시 시간을 잰다. Working set에 속한 pages는 메모리에 유지시키지만,  속하지 않으면 replace해도 된다.

만약 프로세스가 *working set*에 해당되는 모든 page들을 한번에 할당이 불가능할 경우 할당된 모든 frame을 반납한후 suspended 한다. 반대로 *working set*의 모든 page를 할당하고도 page frame에 여유가 있으면 suspended된 프로세스를 깨워서 그것의 *working set*을 할당한다 (MPD 증가)

> **Window Size**: *working set*에 얼마나 오래 머무를수 있는지 결정하는 시간 단위. 값이 너무 작으면 *window set*을 다 수용하지 못할수도 있고, 너무 크면 특정 프로세스에게 너무 많은 page frame 할당이 된다.

#### Page-Fault Frequency (PFF) Scheme

*Page fault*가 자주 발생하는 프로세스에게 더 많은 *page frame*을 할당하고, 그렇지 않은 프로세스에게는 할당된 frame 수를 줄인다. 상한값과 하한값을 두어서 상한값 초과할경우 추가로 할당, 하한값보다 미만일 경우 반대로 할당값을 줄인다. 만약 추가로 할당할 frame이 없는 경우, 그 프로세스에게 할당된 모든 frame을 반납 시키고 suspend.

#### Determining page size

일반적으로 page당 크기는 4Kb이지만, 요즘 트렌드는 점점더 page의 크기를 증가 시키는 추세이다.

Page의 크기가 감소의 장점
- Page의 수가 증가함으로 page table의 크기도 증가.
- 활용되지 못하고 남아있는 공간이 절약됨으로 내부 조각도 감소한다.
- 새로운 page를 메모리에 올릴때 더 적은 양의 정보를 가져옴으로 메모리 절약.
- Locality 측면에서 더 많은 page를 참조해야함으로 disk seek에 필요한 시간이 증가함으로 disk I/O의 효율성이 감소한다.
